{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from copy import copy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/SMSSpamCollection\"\n",
    "stopWords = set(stopwords.words('english'))\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Препроцессинг данных. Чистим строки от мусора, приводим слова в инфинив и в нижний регистр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCyrWord(word):\n",
    "    return word.isalpha()\n",
    "\n",
    "def normalizer(text):\n",
    "    lower = (word.lower() for word in nltk.wordpunct_tokenize(text))\n",
    "    cyr = (word for word in lower if isCyrWord(word))\n",
    "    norm_form = (morph.parse(word)[0].normal_form for word in cyr)\n",
    "    return ' '.join(norm_form)\n",
    "\n",
    "def text_proccesing(text, stopWords):\n",
    "    text_procces = \"\"\n",
    "    \n",
    "    text = re.search('\\t.*\\\\n', line)[0][1:-1]\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
    "    text = re.sub('@[^\\s]+', 'USER', text)\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я]+', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    for t in text.split():\n",
    "        if t not in stopWords:\n",
    "            text_procces = \" \".join((text_procces, t))\n",
    "    return text_procces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем данные и обрабатываем их (препроцессинг)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"labels\": [], \"text\": []}\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    data_file = f.readlines()\n",
    "    for line in data_file:\n",
    "        data['labels'].append(re.match('.*\\\\t', line)[0][:-1])\n",
    "        data['text'].append(normalizer(text_proccesing(line, stopWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку на train и valid. Смотрим как работает Наивный Байес из коробки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9605381165919282\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(data['text'], data['labels'], test_size=0.2, random_state=43)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "clf = Pipeline([('tfidf', TfidfVectorizer()), ('nb', MultinomialNB())])\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_valid)\n",
    "score = metrics.f1_score(y_valid, pred, average=\"micro\")\n",
    "print(f\"F1 Score: {score}\")\n",
    "#temp_valid = np.array([0 if t=='ham' else 1 for t in y_valid])\n",
    "#temp_pred = np.array([0 if t=='ham' else 1 for t in pred])\n",
    "#print(metrics.accuracy_score(temp_valid, temp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция кроссвалидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kcrossvalid(labels, text, kfold = 5):\n",
    "    X = np.array(text)\n",
    "    Y = np.array(labels)\n",
    "    if len(X) == len(Y):\n",
    "        klen = len(X) // kfold\n",
    "        shuffled = np.array(list(range(len(X))))\n",
    "        np.random.shuffle(shuffled)\n",
    "        folds = []\n",
    "        for i in range(kfold-1):\n",
    "            folds.append(shuffled[klen*i:klen*(i+1)])\n",
    "        folds.append(shuffled[klen*(kfold-1):])\n",
    "        folds = np.array(folds)\n",
    "        \n",
    "        res_roc = []\n",
    "        res_acc = []\n",
    "        res_f1 = []\n",
    "        for i in range(kfold):\n",
    "            test = folds[i]\n",
    "            h = list(range(kfold))\n",
    "            h.pop(i)\n",
    "            train = np.concatenate(folds[h])\n",
    "            cls = NB_classifier()\n",
    "            cls.fit(X[train], Y[train])\n",
    "            pred = cls.predict(X[test])\n",
    "            pred_ = [1 if l ==\"spam\" else 0 for l in pred]\n",
    "            y_valid_ = [1 if l ==\"spam\" else 0 for l in Y[test]]\n",
    "            res_roc.append( metrics.roc_auc_score(y_valid_, pred_) )\n",
    "            res_f1.append( metrics.f1_score(y_valid_, pred_) )\n",
    "            res_acc.append( metrics.accuracy_score(y_valid_, pred_) )\n",
    "        return np.array(res_roc), np.array(res_f1), np.array(res_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс нашего Наивного Байеса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics = {'ham': 0, 'spam': 0}\n",
    "class NB_classifier():\n",
    "    def __init__(self):\n",
    "        self.topics = None\n",
    "        self.words = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, Y, topics_c = {'ham': 0, 'spam': 0}):\n",
    "        topics = copy(topics_c)\n",
    "        wtopics = copy(topics)\n",
    "        words = {}\n",
    "        labels = Y\n",
    "        lines = X\n",
    "        for i in range(len(lines)):\n",
    "            topics[labels[i]] += 1\n",
    "            for w in lines[i].split():\n",
    "            \n",
    "                if w in words.keys():\n",
    "                    words[w][labels[i]] += 1\n",
    "                else:\n",
    "                    words[w] = copy(wtopics)\n",
    "                    words[w][labels[i]] += 1\n",
    "\n",
    "        disc = np.array(list(topics.values())).sum()\n",
    "        topics['spam'] /= disc\n",
    "        topics['ham'] /= disc\n",
    "        \n",
    "        for k in words:\n",
    "            sum = 0\n",
    "            for i in words[k]:\n",
    "                sum += words[k][i]\n",
    "            for i in words[k]:\n",
    "                words[k][i]=words[k][i]/sum\n",
    "        self.words = words\n",
    "        self.topics = topics\n",
    "        \n",
    "    def predict(self, X, Topics = ['spam', 'ham']):\n",
    "        def probability_log(val):\n",
    "            if val < 10**(-7):\n",
    "                val = 10**(-7)\n",
    "            return -np.log(val)\n",
    "        \n",
    "        result = []\n",
    "        for line in X:\n",
    "            minimum = 9000000\n",
    "            current_topic = Topics[0]\n",
    "            for t in Topics:\n",
    "                temp = probability_log(self.topics[t])\n",
    "                for w in line.split():\n",
    "                    try:\n",
    "                        temp += probability_log(self.words[w][t])\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "                if temp < minimum:\n",
    "                    current_topic = t\n",
    "                    minimum = temp\n",
    "            result.append(current_topic)\n",
    "        return result   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект нашего классификатора и смотрим на его точность работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794326241134752"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = NB_classifier()\n",
    "cls.fit(x_train, y_train)\n",
    "pred = cls.predict(x_valid)\n",
    "pred_ = [1 if l ==\"spam\" else 0 for l in pred]\n",
    "y_valid_ = [1 if l ==\"spam\" else 0 for l in y_valid]\n",
    "metrics.f1_score(y_valid_, pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8984375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_valid_, pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Различные метрики на кроссвалидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc-auc: [0.92441652 0.91455298 0.93614799 0.90879684 0.85358462], average: 0.907499791179575 \n",
      " F1_Score: [0.91333333 0.89855072 0.92907801 0.89138577 0.81781377], average: 0.8900323210255721 \n",
      " Accuracy: [0.97666068 0.97486535 0.98204668 0.97396768 0.95974955], average: 0.9734579895491757\n"
     ]
    }
   ],
   "source": [
    "res = kcrossvalid(**data)\n",
    "print(f\"Roc-auc: {res[0]}, average: {res[0].mean()} \\n F1_Score: {res[1]}, average: {res[1].mean()} \\n Accuracy: {res[2]}, average: {res[2].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
